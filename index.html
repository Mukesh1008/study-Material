<!DOCTYPE html>
<html lang="en" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BDA - Last Minute Study Guide</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <!-- Chosen Palette: Dark Midnight -->
    <!-- Application Structure Plan: The SPA is designed as a one-page scroller with a sticky navigation bar for quick access to key study areas. The structure is thematic, mirroring the first two chapters of the syllabus: 1) Introduction to Big Data, and 2) Hadoop Fundamentals. This non-linear, task-oriented structure allows a student to jump directly to a weak area, maximizing last-minute study efficiency. The interactive elements (tabs and expandable details for questions) are chosen to break down complex information and provide immediate feedback, aiding rapid learning. A new JavaScript function ensures only one question is open at a time for better focus. -->
    <!-- Visualization & Content Choices: 
        - 5Vs of Big Data: Report Info -> Characteristics of Big Data -> Goal: Organize -> Viz/Method: HTML/CSS list with icons -> Interaction: None -> Justification: A list with icons is the clearest way to present these key concepts for memorization.
        - Evolution of Big Data: Report Info -> History of Big Data -> Goal: Change over time -> Viz/Method: Simple timeline diagram using HTML/CSS -> Interaction: None -> Justification: A visual timeline makes it easy to understand the progression of the field.
        - Hadoop Components: Report Info -> Core components of Hadoop -> Goal: Organize -> Viz/Method: HTML/CSS diagram showing the relationship between HDFS and MapReduce -> Interaction: None -> Justification: A simple diagram is the best way to visualize a system's architecture for beginners.
        - Questions & Answers: Report Info -> Key exam topics -> Goal: Review -> Viz/Method: Expandable questions using <details> tags -> Interaction: User clicks to reveal answers -> Justification: This pattern efficiently hides detailed answers, allowing for a clean, scannable page and active recall, while the new JavaScript logic keeps only one open for better focus.
    -->
    <!-- CONFIRMATION: NO SVG graphics used. NO Mermaid JS used. -->
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #0F172A;
            color: #E2E8F0;
        }
        .nav-link {
            transition: all 0.3s ease;
        }
        .nav-link:hover, .nav-link.active {
            color: #2DD4BF;
            transform: translateY(-2px);
        }
        .card {
            background-color: #1A2035;
            border-radius: 12px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.3);
            border: 1px solid #334155;
            transition: all 0.3s ease;
        }
        .card:hover {
            box-shadow: 0 8px 24px rgba(0,0,0,0.4);
            transform: translateY(-4px);
        }
        details summary {
            cursor: pointer;
            list-style: none;
            padding: 1rem;
            border-bottom: 1px solid #334155;
            transition: background-color 0.2s ease;
            position: relative;
        }
        details summary::-webkit-details-marker {
            display: none;
        }
        details[open] summary {
            background-color: #1E293B;
            border-bottom: 1px solid transparent;
        }
        details summary::after {
            content: 'â–¼';
            position: absolute;
            right: 1rem;
            top: 50%;
            transform: translateY(-50%) rotate(0deg);
            transition: transform 0.2s ease;
            font-size: 0.75rem;
        }
        details[open] summary::after {
            transform: translateY(-50%) rotate(180deg);
        }
        .icon {
            font-size: 1.5rem;
            color: #2DD4BF;
        }
        .timeline-container {
            position: relative;
            padding-left: 1.5rem;
            border-left: 2px solid #334155;
        }
        .timeline-item {
            position: relative;
        }
        .timeline-item::before {
            content: '';
            position: absolute;
            left: -1.5rem;
            top: 0.5rem;
            width: 12px;
            height: 12px;
            background-color: #2DD4BF;
            border-radius: 50%;
            border: 2px solid #1A2035;
        }
    </style>
</head>
<body class="antialiased">

    <header class="bg-gray-800/80 backdrop-blur-lg sticky top-0 z-50 shadow-sm">
        <nav class="container mx-auto px-6 py-4 flex justify-between items-center">
            <h1 class="text-xl font-bold text-gray-200">BDA Study Guide</h1>
            <div class="hidden md:flex space-x-8">
                <a href="#intro" class="nav-link text-gray-400 font-medium">Intro to Big Data</a>
                <a href="#hadoop" class="nav-link text-gray-400 font-medium">Hadoop Basics</a>
                <a href="#mapreduce" class="nav-link text-gray-400 font-medium">MapReduce</a>
            </div>
            <div class="md:hidden">
                <select id="mobile-nav" class="block w-full rounded-md border-gray-600 shadow-sm bg-gray-700 text-gray-200 focus:border-teal-500 focus:ring-teal-500">
                    <option value="#intro">Intro to Big Data</option>
                    <option value="#hadoop">Hadoop Basics</option>
                    <option value="#mapreduce">MapReduce</option>
                </select>
            </div>
        </nav>
    </header>

    <main class="container mx-auto px-6 py-12">
        <div class="text-center mb-16">
            <h2 class="text-4xl font-extrabold text-gray-100 tracking-tight">Big Data Analysis</h2>
            <p class="mt-4 text-lg text-gray-400 max-w-2xl mx-auto">A comprehensive set of 30 questions covering the first two chapters of your syllabus for your mid-semester exam.</p>
        </div>

        <section id="intro" class="mb-20 scroll-mt-24">
            <h3 class="text-3xl font-bold text-center mb-2 text-gray-200">1. Introduction to Big Data (Q1-10)</h3>
            <p class="text-center text-gray-400 mb-12 max-w-3xl mx-auto">This section covers the foundational concepts of Big Data, its characteristics, and why traditional methods can't handle it.</p>
            <div class="card p-8 space-y-4">
                <details>
                    <summary class="font-semibold text-gray-200">1. What is Big Data? Explain its three main characteristics (3Vs).</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2"><strong>Big Data</strong> refers to extremely large and complex datasets that cannot be managed or processed by traditional database systems. The three main characteristics are:</p>
                        <ul class="list-disc list-inside space-y-1">
                            <li><strong>Volume:</strong> The huge amount of data being generated every second.</li>
                            <li><strong>Velocity:</strong> The high speed at which data is created, collected, and needs to be processed.</li>
                            <li><strong>Variety:</strong> The different types of data, from structured (like a database) to unstructured (like photos, videos, or text).</li>
                        </ul>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">2. Why can't traditional database systems handle Big Data?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">Traditional systems (like a single SQL database) were built for a smaller amount of structured data. They cannot handle the huge volume, fast speed, and different types of data that make up Big Data. They are not designed to scale easily across many computers.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">3. What is the difference between structured and unstructured data?</summary>
                    <div class="p-4 bg-gray-700">
                        <ul class="list-disc list-inside space-y-1">
                            <li><strong>Structured data</strong> has a fixed format and is organized in a clear way, like rows and columns in a spreadsheet or database.</li>
                            <li><strong>Unstructured data</strong> has no predefined format. It includes things like social media posts, emails, videos, and images.</li>
                        </ul>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">4. Explain the concept of "Veracity" in Big Data.</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2"><strong>Veracity</strong> refers to the quality and trustworthiness of the data. Because Big Data comes from many different sources, it can be messy, noisy, and unreliable. Veracity is about ensuring the data is accurate enough for analysis.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">5. What is "Data Science"?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from data. It combines statistics, computer science, and domain knowledge to analyze data.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">6. Give three examples of Big Data in the real world.</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">Examples of Big Data include:</p>
                        <ul class="list-disc list-inside space-y-1">
                            <li>Social media platforms (billions of posts, likes, shares).</li>
                            <li>IoT sensors in smart homes and industrial equipment (constant streams of data).</li>
                            <li>E-commerce sites (customer clickstreams, purchase history, and product views).</li>
                        </ul>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">7. What is the role of a "Data Analyst"?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">A Data Analyst's job is to collect, clean, and interpret data to answer specific questions and help with decision-making. They use tools to find patterns and trends in data and present their findings in an easy-to-understand way, often with reports and dashboards.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">8. How did the need for Big Data come about?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">The need for Big Data arose from the explosion of information from sources like the internet, mobile devices, social media, and sensors. The old methods could not keep up with the sheer volume and speed of this new data, so new technologies were needed to analyze it.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">9. What is the main idea behind "Distributed File Systems"?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">The main idea is to store large files not on a single machine, but by splitting them into smaller pieces and storing those pieces across many different computers in a cluster. This allows for parallel processing and is a foundation for Big Data analysis.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">10. What is "semi-structured" data? Give an example.</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">Semi-structured data does not have a formal table structure but has some organizational properties that make it easier to analyze than unstructured data. An example is a **JSON file** or an XML document, which uses tags to organize data but does not have a fixed schema.</p>
                    </div>
                </details>
            </div>
        </section>

        <section id="hadoop" class="mb-20 scroll-mt-24">
            <h3 class="text-3xl font-bold text-center mb-2 text-gray-200">2. Hadoop Fundamentals (Q11-20)</h3>
            <p class="text-center text-gray-400 mb-12 max-w-3xl mx-auto">This section introduces Hadoop, the most important technology in Big Data. You'll learn about its architecture, its key components, and why it's so popular.</p>
            <div class="card p-8 space-y-4">
                <details>
                    <summary class="font-semibold text-gray-200">11. What is Hadoop? Explain its main purpose.</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2"><strong>Hadoop</strong> is a collection of open-source software utilities that allows for the distributed processing of very large datasets across computer clusters. Its main purpose is to solve the problem of storing and processing Big Data cheaply and efficiently by using a cluster of low-cost computers.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">12. What are the two core components of Hadoop?</summary>
                    <div class="p-4 bg-gray-700">
                        <ul class="list-disc list-inside space-y-1">
                            <li><strong>HDFS (Hadoop Distributed File System):</strong> The storage layer that handles storing data across many machines.</li>
                            <li><strong>MapReduce:</strong> The processing layer that handles the logic of analyzing the data.</li>
                        </ul>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">13. Explain the basic idea of HDFS.</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">HDFS is a file system designed to store very large files across many machines in a cluster. It splits large files into smaller blocks and stores these blocks on different computers. It also makes copies of each block for fault tolerance, so if one machine fails, the data is not lost.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">14. What are the two main types of nodes in an HDFS cluster?</summary>
                    <div class="p-4 bg-gray-700">
                        <ul class="list-disc list-inside space-y-1">
                            <li><strong>Namenode:</strong> This is the "master" node. It stores the metadata of the file system, like the names of files, their permissions, and where their blocks are stored. There is only one Namenode per cluster.</li>
                            <li><strong>Datanode:</strong> These are the "worker" nodes. They are the computers that actually store the data blocks of the files. There are many Datanodes in a cluster.</li>
                        </ul>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">15. Explain the concept of "fault tolerance" in HDFS.</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">Fault tolerance means the system can continue to work even if some parts fail. HDFS achieves this by making multiple copies (usually three) of each data block and storing them on different Datanodes. If one Datanode fails, the data can be recovered from the other copies.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">16. What is the key role of MapReduce in Hadoop?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">MapReduce is a programming model for processing large datasets in parallel. It has two main phases: the **Map** phase and the **Reduce** phase. The Map phase breaks down the problem, and the Reduce phase combines the results to solve it.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">17. Explain the "Map" phase of a MapReduce job.</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">In the Map phase, the input data is divided into smaller chunks. The system then runs a "mapper" function on each chunk in parallel. The mapper processes the data and outputs a set of key-value pairs, which are intermediate results.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">18. Explain the "Reduce" phase of a MapReduce job.</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">In the Reduce phase, all the key-value pairs from the Map phase that have the same key are grouped together. A "reducer" function is then run on each group to combine the data and produce the final output.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">19. What is a "JobTracker" and a "TaskTracker"?</summary>
                    <div class="p-4 bg-gray-700">
                        <ul class="list-disc list-inside space-y-1">
                            <li><strong>JobTracker:</strong> The master service that manages all MapReduce jobs in the cluster. It schedules jobs, monitors their progress, and handles failures.</li>
                            <li><strong>TaskTracker:</strong> The worker service that runs on each Datanode. It receives tasks from the JobTracker and executes them.</li>
                        </ul>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">20. What is the key advantage of Hadoop's architecture?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">The key advantage is its **linear scalability**. You can simply add more low-cost computers (Datanodes) to the cluster to increase both storage and processing power. This makes it a very cost-effective way to handle huge amounts of data.</p>
                    </div>
                </details>
            </div>
        </section>

        <section id="mapreduce" class="mb-20 scroll-mt-24">
            <h3 class="text-3xl font-bold text-center mb-2 text-gray-200">3. MapReduce in Detail (Q21-30)</h3>
            <p class="text-center text-gray-400 mb-12 max-w-3xl mx-auto">This section dives deeper into the MapReduce process, covering its internal workings and key concepts for processing data.</p>
            <div class="card p-8 space-y-4">
                <details>
                    <summary class="font-semibold text-gray-200">21. What is the "InputFormat" in MapReduce?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">The **InputFormat** is a component that defines how the input data is split into "InputSplits." These splits are then given to the mappers for processing. For example, a `TextInputFormat` splits a file into lines of text.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">22. Explain the "shuffle and sort" phase in MapReduce.</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">This is the phase between the Map and Reduce steps. The system collects the output key-value pairs from all the mappers, sorts them by key, and then groups all pairs with the same key together. This grouped data is then sent to a specific reducer to be processed.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">23. What is a "combiner" in MapReduce?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">A combiner is an optional function that runs on the mapper machine after the Map phase. It performs a local "reduce" operation to combine the intermediate key-value pairs before they are sent over the network to the reducers. This helps reduce network traffic and speeds up the job.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">24. What are "key-value" pairs in MapReduce?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">Key-value pairs are the fundamental data structure used by MapReduce. The mapper processes the input data and outputs key-value pairs, and the reducer receives and processes key-value pairs as its input.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">25. Give a step-by-step example of a MapReduce job to count words in a file.</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">1. **Map Phase:** A mapper reads a line of text, splits it into individual words, and for each word, outputs a key-value pair like `(word, 1)`. For "Hello world", it would output `(Hello, 1)` and `(world, 1)`.<br>2. **Shuffle & Sort:** All `(word, 1)` pairs are grouped by their word. All `(Hello, 1)` pairs go to one reducer, and all `(world, 1)` pairs go to another.<br>3. **Reduce Phase:** The reducer counts all the '1's for a given word and outputs a final count, like `(Hello, 10)`.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">26. What is the main drawback of MapReduce?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">The main drawback is its complexity. Writing MapReduce jobs can be difficult and time-consuming. It is also not well-suited for interactive, real-time queries or for jobs that require multiple, chained steps.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">27. What is "data locality"?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">Data locality is the principle of moving the computation to the data, rather than the other way around. In Hadoop, the MapReduce framework tries to run a mapper task on the same machine where the data block is stored. This reduces network traffic and makes the job run much faster.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">28. What is the role of the "Job History Server"?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">The Job History Server stores all the logs and records of completed MapReduce jobs. This allows administrators to later analyze a job's performance, debug failures, and understand resource usage.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">29. What is the difference between a "job" and a "task"?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">A **job** is the complete MapReduce program that is submitted by the user. A **task** is a smaller, individual piece of a job. A job is made up of multiple Map tasks and multiple Reduce tasks.</p>
                    </div>
                </details>
                <details>
                    <summary class="font-semibold text-gray-200">30. Why is Hadoop a cost-effective solution for Big Data?</summary>
                    <div class="p-4 bg-gray-700">
                        <p class="mb-2">Hadoop is cost-effective because it is designed to run on a cluster of standard, low-cost computers (commodity hardware) rather than a single, expensive supercomputer. It uses software to handle the complexity and reliability issues, making the hardware costs much lower.</p>
                    </div>
                </details>
            </div>
        </section>
    </main>
    
    <footer class="text-center py-8 text-gray-500 text-sm">
        <p>Good luck with your exam! Built for a Parul University student.</p>
    </footer>

<script>
document.addEventListener('DOMContentLoaded', function () {
    const mobileNav = document.getElementById('mobile-nav');
    mobileNav.addEventListener('change', (e) => {
        const targetId = e.target.value;
        const targetElement = document.querySelector(targetId);
        if(targetElement) {
            targetElement.scrollIntoView({ behavior: 'smooth' });
        }
    });

    const sections = document.querySelectorAll('section');
    const navLinks = document.querySelectorAll('.nav-link');
    
    window.addEventListener('scroll', () => {
        let current = '';
        sections.forEach(section => {
            const sectionTop = section.offsetTop;
            if (pageYOffset >= sectionTop - 150) {
                current = section.getAttribute('id');
            }
        });
        navLinks.forEach(link => {
            link.classList.remove('active');
            if (link.getAttribute('href') === `#${current}`) {
                link.classList.add('active');
            }
        });
    });

    const allDetails = document.querySelectorAll('details');
    allDetails.forEach(details => {
        details.addEventListener('toggle', (event) => {
            if (event.target.open) {
                allDetails.forEach(otherDetails => {
                    if (otherDetails !== event.target && otherDetails.open) {
                        otherDetails.open = false;
                    }
                });
            }
        });
    });
});
</script>
</body>
</html>
